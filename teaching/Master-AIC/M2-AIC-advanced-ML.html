<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
   <TITLE>Learning Theory and Advanced Machine Learning course</TITLE>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
   <META NAME="GENERATOR" CONTENT="User-Agent: Mozilla/3.0Gold (Macintosh; I; PPC)">
</HEAD>
<BODY>

<H2 ALIGN=CENTER><FONT COLOR="#1C74BD">Course Master AI: Learning Theory and Advanced Machine
    Learning</FONT></H2>

<CENTER><P>
<HR WIDTH="100%"><p></P></CENTER>
<CENTER>
<P><font face="Georgia, Times New Roman, Times, serif">Master 2 Informatique - Specialty AI (Course <em>Learning Theory and Advanced Machine Learning</em>)</font></P>
</CENTER>

<CENTER>
  <P><font face="Georgia, Times New Roman, Times, serif">Winter quarter 2025-2026</font></P>
</CENTER>

<CENTER>
  <P><font face="Georgia, Times New Roman, Times, serif">Teacher</font><font face="Georgia, Times New Roman, Times, serif">:&nbsp;&nbsp;&nbsp;<b> <font color="#000099">Antoine
          Cornu&eacute;jols</font></b>  </P>
</CENTER>

<!-- ==================================================================== -->
<P>
<HR WIDTH="100%">

<table width="100%" border="0" height="64" bordercolordark="#CCCCCC" name="Identit&eacute;">
  <tr>
    <td width="63%" height="30">
      <div align="center"><b><a href="https://antoinecornuejols.github.io/">Homepage</a></b> </div>
    </td>
    <td width="37%" height="30"> 
      <div align="center"><img src="../../ID-photo-USA-08-1.jpg" width="44" height="56"></div>
    </td>
  </tr>
</table>

<table width="100%" border="2" cellpadding = 3 cellspacing = 1 bordercolorlight="#CCCCCC" bordercolordark="#999999">
  <tr bgcolor="#FFCC99" align="center">
    <td width = 20%> <a href="#program">Program of the class</a> </td>
    <td width = 20%> <a href="#schedule">Tentative schedule of the classes</a> </td>
    <td width = 20%> <a href="#references">References</a> </td>
    <td width = 20%> <a href="#Etudebiblio">Articles to chose from</a> </td>
    <td width = 20%> <a href="#Projets">Projects</a> </td>
    <td width = 20%> <a href="#Stages">Internships</a> </td>
  </tr>
</table>

<p><font color="#CC3333">Last update: &nbsp;<!-- #BeginDate format:En2 -->14-January-2026<!-- #EndDate --> 
  </font></P>

<H3>Course Organization:</H3>

<ul>
        <li><b>&nbsp;Evaluation </b><!-- (<font color="#FF0000">ATTENTION nouveau</font>)</b>--> : 
        </li>
        <ul>
          <li>&nbsp;Quiz &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: 5 * 6% = 30%</li>
           <li>&nbsp;Project replication of the results of a scientific paper + critical analysis  &nbsp;&nbsp;&nbsp;: 70%  &nbsp;&nbsp; (groups of 4 students)</li>
        </ul>
      <blockquote>
        <p>		</p>
      </blockquote>
      <li>&nbsp;<strong>Documents</strong> : </li>
  <ul>
    <li>&nbsp;Slides of the courses (see below in the course's schedule)</li>
<!--     <li>&nbsp;<a  href=M2-AIC_2017-2018-notes(app-avanc).pdf>Grades for the quizz 1, 2 and 3</a></li>
 -->
   </ul>
</ul>

<HR WIDTH="100%">

<!-- ==================================================================== -->
<H3>Outline of the course:  <a name="program" id="program"></a></H3>
<ol>
  <li>
    <b style="color:#3397AD";>Classical inductive learning: I.I.D.</b>
    <ul>
      <li>
        Basic assumptions
      </li>
      <li>
        What kinds of guarantees
      </li>
       <li>
        Transductive learning
      </li>
       <li>
        Types of distribution shifts and transfer learning (Out-of-Distribution (O.O.D.))
      </li>
     </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Using O.O.D. learning to help solve an I.I.D. learning task</b>
    <ul>
      <li>
        Semi-supervised learning (passive approach)
      </li>
      <li>
        Imbalanced classes (active approach)
      </li>
       <li>
        Active learning (active approach)
      </li>
       <li>
        LUPI (Learning Using Privileged Information)
      </li>
       <li>
        Multi-agent O.O.D. methods in the I.I.D. scenario
         <ul>
           <li>
            Boosting
           </li>
           <li>
            Co-learning
           </li>
           <li>
            Blending
           </li>
         </ul>

      </li>
     </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>O.O.D. at testing time</b>
    <ul>
      <li>
        Designed to stem learning: Adversarial examples
      </li>
      <li>
        Co-variate shift (or domain adaptation)
      </li>
      <li>
        A special case: Tracking
      </li>
    </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>O.O.D. in transfer learning (and multi-tasks learning)</b>
    <p>Using the assumption that there is something in common between the source and the target, what can be transfered includes:</p>
    <ul>
      <li>
        A representation
      </li>
      <li>
        The decision function
      </li>
      <li>
        Something invariant, for instance causality relationships
      </li>
      <li>
        Others: the loss function, the optimizer, â€¦ 
      </li>
    </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Analogy making</b>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Learning with a teacher: distillation</b>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Curriculum learning</b>
    <ul>
      <li>
        A teacher
      </li>
      <li>
        Interferences between tasks
        <ul>
          <li>
            Measuring the difficulty of new examples
          </li>
          <li>
            Catastrophic forgetting
          </li>
          <li>
            A geometry on the space of tasks
          </li>
          <li>
            The geometry can be non Euclidean. The path itself (order of tasks) conveys information
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Online learning</b>
    <ul>
      <li>
        Can we still guarantee something if the teacher acts as an adversary?
      </li>
      <li>
        General empirical approaches to online learning. Solving the plasticity-stability trade-off
      </li>
    </ul>
  </li>
  <br>
  <li>
    <b style="color:#3397AD";>Conclusion</b> 
  </li>
</ol>

<ul>
<!--    <div> <img src="Organisation_Course_AIC.pdf" align="center"  alt="Broad outline the course"  width="75%" height="50%" /></div> 
    <li> Learning is about <strong>extrapolating</strong> predictions and/or regularities from limited data (even if sometimes there is an apparently very large data set) either in a stationary environment (<em>classical induction</em>) or in a changing one (<em>domain adaptation, transfer learning</em>). <br><br>
      This brings <strong>questions</strong> that will be core topics of the course:
    	<br> 
  <ol>
    </li>
    	<br>
    <li> In the case of stationary environments, there is a well developed theory called "the statistical theory of learning", but <b style="color:#3397AD";>what can be done when the environment changes</b> between the <em>training data</em> and the <em>testing one</em>?
    </li>
   <p> </p>	
     <li> Learning may imply several learning agents as in ensemble learning: <b style="color:#3397AD";>what information should they exchange?</b>
    </li>
    <p> </p>	
    <li> Learning may also imply several learning tasks, as in domain adaptation, transfer learning or online learning. Again, <b style="color:#3397AD";>what should be exchanged between contexts?</b>
    </li>
  </ol>
  <br>
  In this class, we will ask ourselves: 
    <ul>
    </li>
      <br>
    <li> <b style="color:#3397AD";>What is transferred in learning</b>, and specially in non stationary environments?
    </li>
   <p> </p> 
     <li> How to measure the <b style="color:#3397AD";>difficulty of learning an example</b>?
    </li>
    <p> </p>  
    <li> What is the best way to <b style="color:#3397AD";>organize a curriculum?</b> Or what is a <b style="color:#3397AD";>good teaching strategy</b>
    </li>
  </ul>

</ul>
-->
<br>

<HR WIDTH="100%">

<!-- ==================================================================== -->
<H3>What you will acquire in the course:  <a name="program" id="program"></a></H3>
<ul>
  <ol>
<!--    <div> <img src="Organisation_Course_AIC.pdf" align="center"  alt="Broad outline the course"  width="75%" height="50%" /></div> -->
    <li> <font color="#000099">
      You will get <b>an understanding of the problem of induction</b>. You will ponder about the kind of guarantees that we can try to obtain as well as to which assumptions should we make and then be aware of when claiming theorems. In order to do so, you will look at the standard statistical learning theory and examine extensions to it.</font> 
    </li>
      <br>
    <li>  <font color="#000099"> You will gain a better appreciation of what is involved in <b>ensemble methods</b> and, in particular, what kind of communication there can be between the agents and how their advices can be combined in order to get a decision.</font>
    </li>
   <p> </p> 
     <li>  <font color="#000099"> You will know what are the problems that face <b>"out of distribution" learning</b>, and get knowledge about some recent directions of research on this problem.</font>
    </li>
    <p> </p>  
    <li>  <font color="#000099"> As part of a project group of students, you will <b>study in depth a recent research paper</b> and try to <b>replicate its results</b>.</font>
    </li>
   <p> </p> 
    <li>  <font color="#000099">As part of a project group of students, you will exercice a <b>critical apparaisal of a research paper</b>.</font>
    </li>
 <!--   <p> </p>  
   <li>  <font color="#000099">You will beneficiate from the results obtained by other groups of students on other research papers.</font>-->
    </li>
  </ol>
  <br>


<!-- ==================================================================== -->

<HR WIDTH="100%">

<table width="100%" border="1">
  <tr> 
    <td width="14%" bgcolor="#CCCCFF"><b><font color="#990000">Dates :</font></b></td>
    <td width="52%" bgcolor="#CCCCFF"><b><font color="#990000">Topics &nbsp;&nbsp;(tentative schedule)</font></b></td>
    <td width="34%" bgcolor="#CCCCFF"><b><font color="#990000">References, exercises and
    homeworks</font></b></td>
  </tr>


<!-- ==================================================================== -->
<!-- ==================================================================== -->
<H3>Tentative schedule:  <a name="schedule" id="schedule"></a></H3>

  <tr> 
    <td width="14%" bgcolor="#D4FCFF"> 
      <p><b>08-01-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>
    <td width="52%" bgcolor="#FFFFFF"> 
      <p align="right">(Antoine Cornu&eacute;jols)</p>
      <p> <b>&nbsp;&nbsp;&nbsp;- </b> Introduction to the course. Out-of-Distribution learning. </p>
        <p> <b>Central question of the course</b>: <em><font color="#000099">What makes you believe that what has been learned so far from (source) training examples or task will be relevant to new (target) examples or tasks? </font></em> </p>

 <ol>
  <li>
    <b style="color:#3397AD";><a href="https:(1)Tr-OOD_intro-induction-2025-26.pdf">Classical inductive learning: I.I.D.</a></b>
    <ul>
      <li>
        Basic assumptions
      </li>
      <li>
        What kinds of guarantees
      </li>
       <li>
        Transductive learning
      </li>
<!--        <li>
        Types of distribution shifts and transfer learning (Out-of-Distribution (O.O.D.))
      </li>
    -->
     </ul>
 </li>
</ol>
    <br>      
        
    <td bgcolor="#FEEAE0">
  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" height="120" bgcolor="#D4FCFF"> 
      <p><b>15-01-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Room C1.2.04 (AgroParisTech)</font>)</p>
    </td>
   <td width="52%" bgcolor="#FFFFFF"> 
      <p align="right">(Antoine Cornu&eacute;jols)</p>
    <ul>
       <li>
        Types of distribution shifts and transfer learning (Out-of-Distribution (O.O.D.))
      </li>
      <br>
    </ul>
      <ol  start="2">
    <li>
      <b style="color:#3397AD";><a href="https:(2)Tr_OOD_for_learning_better-2025-26.pdf">Using O.O.D. learning to help solve an I.I.D. learning task</a></b>
    </li>
    <ul>
      <li>
        Semi-supervised learning (passive approach)
      </li>
      <li>
        Imbalanced classes (active approach)
      </li>
       <li>
        Active learning (active approach)
      </li>
       <li>
        LUPI (Learning Using Privileged Information)
      </li>
       <li>
        <a href="https:(3)Tr_OOD_through_multiple_agents-2025-26-v2(students).pdf">Multi-agent O.O.D. methods in the I.I.D. scenario</a>
         <ul>
           <li>
            Boosting
           </li>
           <li>
            Co-learning
           </li>
           <li>
            Blending
           </li>
         </ul>
       </li>
     </ul>
   </ol>

    <br>      

 
       <br>
 
 <!--       <p><b>&nbsp;&nbsp;&nbsp;- </b>The statistical theory of learning / The no-free-lunch theorem / Another perspective: Explanation-Based-Learning / What kind of validation? -->
    </td>
         
    <td width="34%" bgcolor="#FEEAE0">
          <p>&#149; Quiz No 1</p>
<!--          <p>&#149; <a href="exercice-boosting.pdf">Exercise on boosting</a> </p> 

<p>&#149; -->
         

    </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" height="120" bgcolor="#D4FCFF"> 
      <p><b>22-01-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>

    <td width="52%" bgcolor="#FFFFFF"> 
      <p align="right">(Antoine Cornu&eacute;jols)</p>

    </td>
         
    <td width="34%" bgcolor="#FEEAE0">
          <p>&#149; Quiz No 2</p>
<!--          <p>&#149; <a href="exercice-boosting.pdf">Exercise on boosting</a> </p> 

<p>&#149; <a href="Tr-collaborative_learning-2023-24-v2.pdf">Slides of the class</a>
          <p></p>
-->
    </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" height="120" bgcolor="#D4FCFF"> 
      <p><b>29-01-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>
    
    <td bgcolor="#FFFFFF"><p align="right">(Antoine Cornu&eacute;jols)</p>
    </td>

    <td width="34%" bgcolor="#FEEAE0">
          <p>&#149; Quiz No 3</p>
   </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" bgcolor="#D4FCFF"> 
      <p><b>12-02-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>
    
    <td bgcolor="#FFFFFF""> 
      <p align="right">       (Antoine Cornu&eacute;jols)</p>

    <br>      
    </td>

    <td width="34%" bgcolor="#FEEAE0">
      <p>&#149; Quiz No 4</p>
      <p> <a href="https://seafile.agroparistech.fr/f/c0da1fe0e7534d618c08/">CORNU&Eacute;JOLS, Antoine. <b>Some thoughts about transfer learning. What role for the source domain?</b>. <em>International Journal of Approximate Reasoning</em>, 2024, vol. 166, p. 109107.</a> 
     </p>

    </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" height="120" bgcolor="#D4FCFF"> 
      <p><b>19-02-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>
    
    <td bgcolor="#FFFFFF"><p align="right">(Antoine Cornu&eacute;jols)</p>


    </td>

    <td bgcolor="#FEEAE0">
      <p>&#149; Quiz No 5</p>
      <p><em> <a href="https://eprints.bbk.ac.uk/id/eprint/44038/1/KD_Survey-arxiv.pdf">Gou, J. and Yu, B. and Maybank, Stephen and Tao, Da. (2021) <b>Knowledge distillation: a survey</b>. International Journal of Computer Vision 129, pp.1789-1819.</a></em> 
     </p>
      <p><em> <a href="https://proceedings.mlr.press/v97/phuong19a/phuong19a.pdf">PHUONG, Mary et LAMPERT, Christoph. <b>Towards understanding knowledge distillation</b>. In : International conference on machine learning. PMLR, 2019. p. 5142-5151.</a></em> 
     </p>

      <p> <em> <a href="https://arxiv.org/pdf/2011.00613.pdf">(ICML-2021)-An Information-Geometric Distance on the Space of Tasks</a></em>. 
     </p>
      <p> <em> <a href="https://arxiv.org/pdf/2107.04384.pdf">(ICML-2021)-Continual Learning in the Teacher-Student Setup: Impact of Task Similarity</a></em>. 
      </p>
     </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  <tr> 
    <td width="14%" height="120" bgcolor="#D4FCFF"> 
      <p><b>20-02-2026</b></p>
      <p align="right">09h00 - 12h15  (<font color="#FF0000">Salle B-108</font>)</p>
    </td>
    
    <td bgcolor="#FFFFFF"><p align="right">(Antoine Cornu&eacute;jols)</p>
      <p></p>
    </td>

    <td bgcolor="#FEEAE0">
     <p>&#149; <b>Final reports</b>. Due date: <font color="#FF0000"><blink><b>February, 19th, 2026</b></blink></font></p>
    </td>

  </tr>
<!-- ==================================================================== -->
<!-- ==================================================================== -->
  
  
  
<!-- ==================================================================== -->
<!-- ==================================================================== -->
</table>
<H3>&nbsp;</H3>
<h3>References and web sites: <a name="references" id="references"></a></h3>
<ul>
  <li>&nbsp; Barra V. &amp; Cornu&eacute;jols A. &amp; Miclet L.: <u><font color="#000099">Apprentissage artificiel. Concept et algorithmes. De Bayes et Hume au Deep Learning</font></u>. Eyrolles, 2021 (4&egrave;me &eacute;dition)<br>
  &nbsp; (A very comprehensive book on Machine Learning. In French.)</li>
</ul>
<p>
<ul>
  <li>&nbsp; Torralba A. &amp; Isola Ph. &amp; Freeman W.: <u><font color="#000099">Foundations of Computer Vision</font></u>. MIT Press, 2024.<br>
  &nbsp; (Speaks mainly of computer vison obviously. But an incredible synthesis of learning problems and methods. <br> &nbsp; Highly recommended.)</li>
</ul>

<p><strong>Books on Machine Learning in general</strong>:</p>
<ul>
  <li> &nbsp;Barber D. :<u> Bayesian Learning and Machine Learning</u>. Cambridge
    University Press,
    2012.<br>
    &nbsp;(A Bayesian perspective on Machine Learning.)
</ul>
<ul>
  <li> &nbsp;Bishop Ch. :<u> <font color="#000099">Deep Learning. Foundations and Concepts</font></u>. MIT Press,
    2024.<br>
    &nbsp;(Quite pedagogical.)
</ul>
<ul>
  <li> &nbsp;Duda, Hart &amp; Stork :<u> Pattern classification</u> (2nd &eacute;d.).
    Wiley-Interscience, 2001.<br>
&nbsp;(Oriented towards Pattern Recognition. Very good graphics. Still a reference.)
</ul>
<ul>
  <li>&nbsp;Flach P. : <u>Machine Learning. The art and science of algorithms
        that make sense of data</u>.
      Cambridge University Press, 2012.<br>
&nbsp;(A good introductory book on Machine Learning. Quick on some subjects and
does not really cover data mining. But a very original and often quite illuminating perspective.)</li>
</ul>
<!--
<ul>
  <li>&nbsp;Hand, Mannila &amp; Smyth : <u>Data mining</u>. Springer, 2001.<br>
    &nbsp;(Livre assez complet, mais n&eacute;cessairement plus superficiel car couvrant aussi la fouille de donn&eacute;es)</li>
</ul>
-->
<ul>
  <li>&nbsp;Hastie, Tibshirani &amp; Friedman : <u>The elements of statistical
       learning. Data mining, inference and prediction</u>. Springer, (2nd Ed.
       2009).<br>
    &nbsp;(A bit demanding, but very informative. The form is outstanding.)</li>
</ul>
<ul>
  <li>&nbsp;Haykin S. : <u>Neural netwoks. A comprehensive foundation</u>. Prentice 
    Hall, 1999.<br>
  &nbsp;(An incredible source of information)</li>
</ul>
 <ul>
  <li>&nbsp;Haykin S. : <u>Neural netwoks and Learning Machines</u>. Prentice
    Hall, 2008.<br>
&nbsp;(Different from the 1999 edition, and yet still remarkable, and worth
the reading.)
  </li>
</ul>
<!--
<ul>
  <li> &nbsp;Mitchell T. : <u>Machine Learning</u>. McGraw Hill, 1997. <br>
    &nbsp; (A good introductory book, but outdated on many subjects.)</li>
</ul>
-->
<!--
<ul>
  <li> &nbsp;Marsland S. : <u>Machine Learning. An algorithmic perspective</u>.
    CRC Press, 2009. <br>
    &nbsp; (An introductory book, rather superficial, with bits of code in Python.)</li>
</ul>
-->
<ul>
  <li> &nbsp;Murphy K. : <u>Machine Learning. A probabilistic perspective</u>.
    MIT Press, 2012. <br>
&nbsp; (The title says it all. A book incredibly comprehensive from a Bayesian
perspective.)</li>
</ul>
<ul>
  <li> &nbsp;Murphy K. : <u><font color="#000099">Probabilistic Machine Learning. A introduction</font></u>.
    MIT Press, 2022. <br>
&nbsp; (The new edition, first of two volumes.)</li>
</ul>
<ul>
   <li> &nbsp;Murphy K. : <u><font color="#000099">Probabilistic Machine Learning. Advanced topics</font></u>.
    MIT Press, 2022. <br>
&nbsp; (The new edition, second of two volumes. Lots of recent works. A little bit of a patchwork.)</li>
</ul>
<ul>
   <li> &nbsp;Sejnowski T. : <u><font color="#000099">The deep learning revolution</font></u>.
    MIT Press, 2018. <br>
&nbsp; (Provides a personal historical perspective. By someone who should have shared the 2024 Nobel Prize.)</li>
</ul>
<ul>
   <li> &nbsp;Zou Zhi-Hua. : <u><font color="#000099">Machine Learning</font></u>.
    Springer, 2016. <br>
&nbsp; (A very good introductory book)</li>
</ul>
<p><strong></strong></p>

<p><strong>Books on specific topics</strong>:</p>
<ul>
  <li>&nbsp;Bishop C. : <u>Neural networks for pattern recognition</u>. Clarendon 
    Press, 1995.<br>
&nbsp;(A good introductory book. Oriented towards connectionism but discusses
many important issues in Machine Learning as well.)
  </li>
</ul>
<ul>
  <li>&nbsp;Cristianini N. &amp; Shawe-Taylor J. : <u>Support Vectors Machines
      and other kernel-based learning methods</u>. Cambridge University Press,
      2000.</li>
</ul>
<ul>
  <li>&nbsp;Webb A. : <u>Statistical pattern recognition</u>. Wiley, (3rd. Ed.,
    2011).<br>
    &nbsp;(A good introductory book that deserves to be better known.) <br>
  </li>
</ul>
<!-- <p><strong>Web sites</strong> :</p>
<ul>
  <li>&nbsp;<a href="http://www.ai.univie.ac.at/oefai/ml/ml-resources.html">http://www.support-vector.net</a><br>
    &nbsp; (Un point d'entr&eacute;e sur les machines &agrave; vecteurs de support)</li>
</ul>
<ul>
  <li>&nbsp;<a href="http://www.ai.univie.ac.at/oefai/ml/ml-resources.html">http://www.ai.univie.ac.at/oefai/ml/ml-resources.html</a><br>
    &nbsp; (Un site recensant de tr&egrave;s nombreuses ressources en Apprentissage 
    Artificiel)</li>
</ul>
-->

<!-- ==================================================================== -->
<!-- ==================================================================== -->
<HR WIDTH="100%">
<h3><font color="#000099">Guidelines for the projects<a name="Projets"></a>:</font></h3>
<!-- ==================================================================== -->

This year, your assignment in the projects is to choose an article from the list provided below, understand it, and, most importantly, <strong>try to replicate the experiments</strong>.

<ul></ul>
<br>
Rules are as follows:

<ul>
   <li> Projects are conducted by <strong>team of 4 students</strong>. Team members are responsible for decompose the work so that all members contribute meaningfully to the project.  
   </li>
</ul>
   
<br>
The following deliverables are expected:

<ol>
   <li> Before (<strong><em> <font color="#990000">January 15th 2026 </font></em></strong>), the <strong>choice of the paper</strong> and the names of the members of the team.
   </li>
   <li> (<strong><em> <font color="#990000">February, 19th 2026 </font></em></strong>) <strong> Final report </strong> : 10 pages (strict. Reports longer than 10 pages will not be read!)
   </li>
</ol>

<br>
The intermediary report and the final report must be turned down in the ICML (Int. Conf. on Machine Learning) format for <a href="http://icml.cc/2016/?page_id=151">papers</a>.

<br>
<br>
The deliverables will be evaluated taking into account:

<br>
<br>
<ul>
   <li>
   	The <strong>clarity of the analysis of the chosen article</strong>. The paper should briefly present, in no more than two to four pages (out of the 10 allotted), the problem studied in the article, the main ideas and statements presented in the paper. The remaining pages will present the experiments carried out by the team, the possible difficulties, the results obtained and a comparison with the results presented by the authors of the article used as a basis for the project.
   </li>
   <br>
   <li> 
   	The <strong>rigor</strong> and the extensive character of the analysis and/or the experiments carried out. A project that really answers the questions and possible doubts of the reviewers on the interest of the method and on the announced performances will obtain a higher score.
   </li>
   <br>
   <li> 
   	Expression, <strong>clarity of explanation</strong> and quality of exposition. Reports can be written in French or English, as long as they are clear and well written.
   </li> 
</ul>

<br>


<HR WIDTH="100%">

<strong>List of the papers to chose from</strong><a name="#Etudebiblio" id="Etudebiblio"></a> 
      <br> 
<br>

  <ol>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://arxiv.org/pdf/2506.18221">(2025) These Are Not All the Features You Are Looking For- A Fundamental Bottleneck in Supervised Pretraining</a></em></b>.  
     </li>
<br>
       <li> <b><font color="#FF0000"> <b>Taken </font></b> <em> <a href="https://arxiv.org/pdf/2506.18221">(2022) Emergent world representations- Exploring a sequence model trained on a synthetic task</a></em></b>.  (Playing Othello with LLMs)
     </li>
<br>
       <li> <b><font color="#FF0000"> <b>Taken </font></b> <em> <a href="https://arxiv.org/pdf/2403.15498?">(2022) Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models</a></em></b>. (and the <a href="https://adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html">blog entry</a>, even more detailed.) (Playing Chess with LLMs)
     </li>
<br>
       <li> <b><font color="#FF0000"> <b>Taken </font></b> <em> <a href="https://openreview.net/attachment?id=c9klnr4Cb9&name=pdf">(AAI-2025) Tabular out-of-distribution data synthesis for enhancing robustness</a></em></b>.  (Experiments without deep learning. Interesting nonetheless.)
     </li>
<br>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34841/36996">(AAAI-2025) RUNA- Object-level Out-of-Distribution Detection via Regional Uncertainty Alignment of Multimodal Representations.</a></em></b>.  
     </li>
<br>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32162/34317">(AAAI-2025)-Progressive Self-Learning for Domain Adaptation on Symbolic Regression of Integer Sequences.</a></em></b>.  
     </li>
<br>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://arxiv.org/pdf/2007.01434.pdf">(2020) In search of lost domain generalization</a></em></b>. 
     </li>
<br>
       <li> <b><font color="#FF0000"> <b> </font></b><em> <a href="https://seafile.agroparistech.fr/f/ce4e9558d2b1442a8857/">(ICLR-2024) Self-Supervised Dataset Distillation for Transfer Learning</a></em></b>. (Powerful computational ressources required)
     </li>
<p>
       <li> <b><font color="#FF0000"> <b>Taken </font></b> <em> <a href="https://seafile.agroparistech.fr/f/d4a139ea3b5f43ddb8de/">(ICLR-2024) Transferring Learning Trajectories of Neural Networks</a></em></b>. 
     </li>
<p>
       <li> <b> <em> <a href="https://proceedings.mlr.press/v202/liu23ap/liu23ap.pdf">(ICML-2023) Taxonomy-Structured Domain Adaptation</a></em></b>. 
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://arxiv.org/abs/2302.12091 ">(ICML-2023) Random Teachers are Good Teachers</a></em></b>. 
     </li>
<p>
       <li> <b> <em> <a href="https://arxiv.org/pdf/2306.09890.pdf">(ICML-Workshop-2023) Studying Generalization on Memory-Based Methods in Continual Learning</a></em></b>. 
     </li>
<p>
       <li> <b> <em> <a href="https://seafile.agroparistech.fr/f/7f85c3bfa51e4b50b267/">(ICLR-2024) Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP</a></em></b>. 
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b><em> <a href="https://openreview.net/pdf?id=Oa9RlXNggGy">(Neurips-2022) Does knowledge distillation really works?</a></em></b>. 
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="http://proceedings.mlr.press/v139/lee21e/lee21e.pdf">(ICML-2021) Continual learning in the teacher-student setup: impact of task similarity</a></em></b>. 
     </li>
<p>
       <li> <b></b> <b><em> <a href="https://arxiv.org/pdf/2002.08546.pdf">(ICML-2020) Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation</a></em></b>. (Powerful computational ressources required)
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://arxiv.org/pdf/2007.12684.pdf">(ICCV-2021) Deep co-training with task decomposition for semi-supervised domain adaptation</a></em></b>. 
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://seafile.agroparistech.fr/f/7f3089f7a27241f4894f/">(ICML-2024) Transferring Knowledge From Large Foundation Models to Small Downstream Models</a></em>. 
     </li>
<p>
       <li> <b><P></P></b> <em> <a href="https://seafile.agroparistech.fr/f/33a561fcef034256a522/">(ICML-2024) Pseudo-Calibration-Improving Predictive Uncertainty Estimation in Unsupervised Domain Adaptation</a></em></b>. (Powerful computational ressources required)
     </li>
<p>
       <li> <b><font color="#FF0000"> <b> </font></b> <em> <a href="https://seafile.agroparistech.fr/f/ff552f663abf41e59b69/">(ICML-2024) Let Go of Your Labels with Unsupervised Transfer</a></em>. 
     </li>
<p>
       <li> <b></b> <em> <a href="https://seafile.agroparistech.fr/f/2aa53310fa794b5db619/">(IJCAI-2024) Alleviating Imbalanced Pseudo-label Distribution- Self-Supervised Multi-Source Domain Adaptation with Label-specific Confidence</a></em>. 
     </li>
<p>
    </ol>

   
 

<p>
</p>

<!-- ==================================================================== -->
<!-- ==================================================================== -->
<HR WIDTH="100%">
<H3>Projects chosen by the students:</H3>
  <table width="100%" border="0"  cellspacing="12">
  <tr> 
    <td width="25%" bgcolor="#CCCCFF"><b><font color="#990000">Names :</font></b></td>
    <td width="75%" bgcolor="#CCCCFF"><b><font color="#990000">Projects :</font></b>
  </tr>
<!-- ==================================================================== -->


  <tr>
     <td>
        <li>Kseniia PAVLOVA</li>
        <li>Elizaveta SIROTINA</li>
        <li>Polina SOLOVEVA</li>
        <li>Ekaterina TIMOFEEVA</li>
     </td>
      <td bgcolor="F3F3F3">      
        <li> <em> <a href="https://arxiv.org/pdf/2506.18221">(2022) Emergent world representations- Exploring a sequence model trained on a synthetic task</a></em>. 
        </li>
        <li> (final report: <font color="#3fd859"> </font> <font color="#FF0000"> <b>NO</b> </font>)</li>
      </td>
  </tr>
  
  <tr>
     <td>
        <li>Zhetessov CAREER</li>
        <li>A. ZHAMANKHAN</li>
        <li>Menghor THUO</li>
     </td>
      <td bgcolor="F3F3F3">      
        <li> <em> <a href="https://seafile.agroparistech.fr/f/d4a139ea3b5f43ddb8de/">(ICLR-2024) Transferring Learning Trajectories of Neural Networks</a></em>. 
        </li>
        <li> (final report: <font color="#3fd859"> </font> <font color="#FF0000"> <b>NO</b> </font>)</li>
      </td>
  </tr>

  <tr>
     <td>
        <li>Tristan BOUTEVILLE</li>
        <li>Tom GORTANA</li>
        <li>Nicolas LENGLET</li>
        <li>Donatien WALLAERT</li>
     </td>
      <td bgcolor="F3F3F3">      
        <li> <em> <a href="https://arxiv.org/pdf/2403.15498?">(2022) Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models</a></em>. 
        </li>
        <li> (final report: <font color="#3fd859"> <b></b> </font> <font color="#FF0000"> <b>NO</b> </font>)</li>
      </td>
  </tr>
  
  <tr>
     <td>
        <li>Feddy IMMOULA</li>
        <li>Tyler MARINO</li>
        <li>Thibault POUX</li>
     </td>
      <td bgcolor="F3F3F3">      
        <li> <em> <a href="https://openreview.net/attachment?id=c9klnr4Cb9&name=pdf">(AAI-2025) Tabular out-of-distribution data synthesis for enhancing robustness</a></em>. 
        </li>
        <li> (final report: <font color="#3fd859"> <b></b> </font> <font color="#FF0000"> <b>NO</b> </font>)</li>
      </td>
  </tr>
  
  <tr>
     <td>
        <li>Student-1</li>
        <li>Student-2</li>
        <li>Student-3</li>
        <li>Student-4</li>
     </td>
      <td bgcolor="F3F3F3">      
        <li> <em> <a >(Conference) Paper title</a></em>. 
        </li>
        <li> (final report: <font color="#3fd859"> <b>YES</b> </font> <font color="#FF0000"> <b>NO</b> </font>)</li>
      </td>
  </tr>
  
  </tr>
  


 

<!-- ==================================================================== -->
  </table>
</UL>
<p><br>
  
  
<!-- ==================================================================== -->
<!-- ==================================================================== -->
<HR WIDTH="100%">
<h3><font color="#000099">Propositions for internships<a name="Stages"></a> :</font></h3>
<!-- ==================================================================== -->

<!-- ==================================================================== -->
</table>
<!-- 
<p>&nbsp;</p>
<HR WIDTH="100%">
<H3>Propositions de stages<a name="Stages"></a> :</H3>
-->
<UL>
  <blockquote>
    <p>&nbsp;</p>
  </blockquote>
  <table width="852" border="0" cellspacing="12">
    <!--DWLayoutTable-->
  <!--  <tr>
       <td bgcolor="#F3F3F3"><a href="../STAGES-Master/stage-Orange-flux-data-2018.pdf">Apprentissage &agrave; partir de flux de donn&eacute;s : d&eacute;tection d'anomalies</a></td>
      <td>Orange Labs / AgroParisTech</td>
    </tr>
    <tr>
      <td bgcolor="E9F9F6"><a href="../STAGES-Master/Sujet-Stage Arkyan Classifier Brevet.pdf">Classification automatique de brevets</a></td>
      <td>Arkian (Montpellier)</td>
    </tr>
    <tr>
      <td bgcolor="F3F3F3"><a href="../STAGES-Master/sujet-stage-WP1PhDStage-agro-SHIFT.pdf">Personnalized recommendation system for food choices</td>
      <td>AgroParisTech / Danone</td>
    </tr>
   -->
   <tr>
      <td bgcolor="E9F9F6">sujet</td>
      <td>Institution</td>
    </tr>
    <tr>
      <td bgcolor="F3F3F3">sujet</td>
      <td><p>Institution</p>
      </td>
    </tr>
    <tr>
      <td bgcolor="F3F3F3">sujet</td>
      <td>Institution</td>
    </tr>
    <tr>
      <td bgcolor="F3F3F3">sujet</td>
      <td>Institution</td>
    </tr>
    <tr>
      <td bgcolor="F3F3F3">sujet</td>
      <td>Institution</td>
    </tr>
  </table>
</UL>
<p><br>
</p>
<P>
<!-- ==================================================================== -->



<p>&nbsp;</p>
<p>&nbsp;</p>
</BODY>
</HTML>
